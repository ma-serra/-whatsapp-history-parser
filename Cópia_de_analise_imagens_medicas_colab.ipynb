{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ma-serra/-whatsapp-history-parser/blob/master/C%C3%B3pia_de_analise_imagens_medicas_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4HBDH5mQg52"
      },
      "source": [
        "# MBA FIAP Inteligência Artificial & Machine Learning\n",
        "\n",
        "## Visão Computacional: Análise de Imagens Médicas\n",
        "\n",
        "> Atenção: este notebook foi desenhado para funcionar no **Google Collab**. Se pretende executar localmente prefira a versão local deste notebook, sem o sufixo ```-collab```.\n",
        "\n",
        "\n",
        "## 1. Introdução\n",
        "\n",
        "As tecnologias de imagens médicas estão cada vez mais integradas aos sitemas de visão computacional, incluindo as imagens de raio-x.\n",
        "\n",
        "Modelos de equipamentos modernos geram imagens digitais deste tipo de exame, proporcionando análises mais completas e menos _ad-hoc_, com isso algumas pré-análises podem ser realizadas por aplicações baseadas em inteligência artificial para confirmar ou sugerir diagnósticos ao profissional responsável pelo exame.\n",
        "\n",
        "No campo dos diagósticos por raios-x, a pnenumonia é uma das enfermidades onde seu uso é um dos mais aplicados para determinar o curso de tratamento.\n",
        "\n",
        "<p align=\"center\">\n",
        "    <img src=\"https://github.com/michelpf/fiap-ml-visao-computacional-capstone-alternative/blob/master/projeto-final/imagens/NORMAL2-IM-1422-0001.jpeg?raw=1\">\n",
        "</p>\n",
        "\n",
        "## 2. Instruções\n",
        "\n",
        "Este projeto final tem como objetivo explorar os conhecimentos adquiridos nas aulas práticas.\n",
        "\n",
        "Por meio de uma trilha guiada, iremos constuir um modelo que seja capaz de classificar imagens de raio-x para determinar se a determinada pessoa está com alguma condição que necessita maiores cuidados.\n",
        "\n",
        "De acordo com as imagens disponíveis para o treinamento e validação, será de critério do grupo selecionar as quantidades ideais ou até mesmo pré-processar as imagens para obter o melhor resultado, nos principais indicadores de performance, como precisão, sensibilidade e pontuação F1.\n",
        "\n",
        "Este projeto poderá ser feita por grupos de até 4 pessoas.\n",
        "Caso este projeto seja substitutivo, deverá ser realizado por apenas uma pessoa.\n",
        "\n",
        "| Nome dos Integrantes     | RM            | Turma |\n",
        "| :----------------------- | :------------- | :-----: |\n",
        "| Integrante 1             | RM 12345      | `1IA` |\n",
        "| Integrante 2             | RM 12345      | `1IA` |\n",
        "| Integrante 3             | RM 12345      | `1IA` |\n",
        "| Integrante 4             | RM 12345      | `1IA` |\n",
        "\n",
        "Por ser um projeto guiado, fique atento quando houver as marcações **Implementação** indica que é necessário realizar alguma implementação em Python no bloco a seguir onde há a inscrição ```##IMPLEMENTAR``` e **Resposta** indica que é esperado uma resposta objetiva relacionado a algum questionamento.\n",
        "\n",
        "**Cada grupo pode utilizar nas respostas objetivas quaisquer itens necessários que enriqueçam seu ponto vista, como gráficos, fotos e, até mesmo, trechos de código-fonte.**\n",
        "\n",
        "Pode-se utilizar quantos blocos forem necessários para realizar determinadas implementações ou utilizá-las para justificar as respostas. Não é obrigatório utilizar somente o bloco indicado.\n",
        "\n",
        "Ao final não se esqueça de subir os arquivos do projeto nas contas do GitHub de cada membro, ou subir na do representante do grupo e os membros realizarem o fork do projeto.\n",
        "\n",
        "A avaliação terá mais ênfase nos seguintes tópicos de desenvolvimento do projeto:\n",
        "\n",
        "1. __Pré-Processamento__\n",
        "2. __Classificação__\n",
        "3. __Performance__\n",
        "4. __Conclusões Finais__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqbM_NTgQg54"
      },
      "source": [
        "## 3.1 Detalhe do problema: a pneunomia\n",
        "\n",
        "Fonte: [artigo](https://drauziovarella.uol.com.br/doencas-e-sintomas/pneumonia) do Dr. Drauzio Varella.\n",
        "\n",
        "Pneumonias são infecções que se instalam nos pulmões, órgãos duplos localizados um de cada lado da caixa torácica. Podem acometer a região dos alvéolos pulmonares onde desembocam as ramificações terminais dos brônquios e, às vezes, os interstícios (espaço entre um alvéolo e outro).\n",
        "\n",
        "Basicamente, pneumonia é provocada pela penetração de um agente infeccioso ou irritante (bactérias, vírus, fungos e por reações alérgicas) no espaço alveolar, onde ocorre a troca gasosa. Esse local deve estar sempre muito limpo, livre de substâncias que possam impedir o contato do ar com o sangue.\n",
        "\n",
        "Exame clínico, auscultação dos pulmões e radiografias de tórax são recursos essenciais para o diagnóstico de pneumonia.\n",
        "\n",
        "<p align=\"center\">\n",
        "    <img src=\"https://github.com/michelpf/fiap-ml-visao-computacional-capstone-alternative/blob/master/projeto-final/imagens/pneumonia.jpeg?raw=1\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgnN49ZnQg54"
      },
      "source": [
        "## 3.2 Diagnóstico por raio-x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xd01IzxQg54"
      },
      "source": [
        "O exame de raio-x traz diferenças em cada tipo de diagnóstico, sendo considerado os seguintes grupos de análise: **normal** (ou controle) onde não há nenhuma condição de infeção, **bacterial pneumonia** (pneumonia bacteriana) que representa a condição de infecção bacteriana e **viral pneumonia** que indica a condição de infecção vira."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTpC10hkQg55"
      },
      "source": [
        "<p align=\"center\">\n",
        "<img src=\"https://github.com/michelpf/fiap-ml-visao-computacional-capstone-alternative/blob/master/projeto-final/imagens/raiox.png?raw=1\" height=\"60%\" width=\"60%\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8P2ylOqQg55"
      },
      "source": [
        "As imagens de controle não são mais brancas ao centro que é onde fica o coração. Já nas imagens com pneumonia é possível notar regiões brancas ao redor dos pulmões, que é como o exame identifica as secreções responsáveis pela infeçcão.\n",
        "\n",
        "Quando mais regiões brancas ao redor do pulmão mais severa é a inflamação e menos se observa dos detalhes dos pulmões, ficando um pouco esmaecido diante desta condição."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHhi5e-wQg55"
      },
      "source": [
        "## 4.1 Problema\n",
        "\n",
        "Construir um classificador utilizando _transfer learning_ para identificar as seguintes classes: **controle**, **pneumonia bacteriana** e **pneumonia viral**.\n",
        "\n",
        "Para construir este classificador, utilize o dataset do [Kaggle Chest Ray Pneumonia](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia) e organize os dados de forma a separar em cada uma das classes que já estão definidas no diretório ```raiox```, sendo ```controle``` para as imagens normais (sem inflamação), ```bacteria``` para as imagens de pneumonia bacteriana e ```viral``` para as imagens de pneumonia viral.\n",
        "\n",
        "Determine a quantidade de imagens a serem treinadas e validadas. Utiliza pelo menos, 100 imagens para cada classe.\n",
        "\n",
        "Compare os resultados com pelo menos 3 classificadores, obtendo os valores de **precisão (precision)**, **sensibilidade (recall)** e **pontuação F1 (F1 Score)**. No guia abaixo, foi indicado os seguintes modelos: ResNet50, VGG16 e VGG19.\n",
        "\n",
        ">Importante: a escolha do número de imagens devem ser o suficiente para alcançar o valor de **precisão** mínima de 70%.\n",
        "Note que as imagens de pneumonia bacteria e viral estão misturadas dentro da pasta ```PNEUMONIA```. É necessário separar as imagens manualmente tendo como base o sufixo. As imagens que terminal com ```_virus``` se referem a pneumoria viral e as que terminam com ```_bacteria``` se referem a pneumonia bacteriana.\n",
        "\n",
        "A construção do modelo será utilizada o framework Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfpP5mV6Qg55"
      },
      "source": [
        "**Pergunta**: Qual o número de imagens que foram selecionadas para cada classe?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhmYDqQqQg55"
      },
      "source": [
        "**Resposta**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bMT6hOmQg55"
      },
      "source": [
        "## 4.2 Componentes obrigatórios\n",
        "\n",
        "Todas as bibliotecas já estão instaladas no Google Colab.\n",
        "\n",
        "* Keras\n",
        "* Tensorflow\n",
        "* Pillow\n",
        "* Matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bn3HjVfWQg55"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras.models import Sequential, load_model, model_from_json\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Activation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16, ResNet50, VGG19\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras import Model, layers\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "import tensorflow.keras.backend as K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjGDMeniQg56"
      },
      "source": [
        "## 4.3 Carregando imagens de treinamento e validação\n",
        "\n",
        "Selecione a melhor divisão entre dados de treinamento e validação. O número deverá ser representado em número fracionário, 5% equivale a 0.05, por exemplo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hYD4rR2Qg56"
      },
      "source": [
        "> Você pode _montar_ o drive do Google Drive se precisar e quiser armazenar as imagens nesta plataforma. Como o Colab é efêmero, se você copiar os arquivos para o ambiente eles serão apagados depois do fim da sessão. Acesse [esta](https://medium.com/@maxwellcsm/colaboratory-acessando-os-arquivos-do-google-drive-d08ef9157dbf) referência para saber mais como o recurso funciona, inclusive recomenda-se essa abordagem de montar o próprio Google Drive.\n",
        "\n",
        "Se não for utilizar o Google Drive, crie as pastas que serão utilizadas para armazenar as imagens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbIR5vhwQg56"
      },
      "source": [
        "### 4.3.1 Utilizando Google Drive\n",
        "\n",
        "Se usar o Google Drive para armazenar as imagens utilize o comando abaixo para montar seu drive.\n",
        "Você pode navegar pelas pastas pelo painel ao lado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "encabnBnQg56"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMzoCONKQg56"
      },
      "source": [
        "### 4.3.2 Utilizando o armazenamento efêmero\n",
        "\n",
        "Se optar pelo armazenamento efêmero você precisa enviar os arquivos de imagens (arrastar e soltar) para as pastas que deverão ser criadas pelo comando a seguir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDElt2_GQg56"
      },
      "outputs": [],
      "source": [
        "!mkdir raiox/\n",
        "!mkdir raiox/normal\n",
        "!mkdir raiox/pneumonia_bacteriana\n",
        "!mkdir raiox/pneumonia_viral"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyidIbQAQg56"
      },
      "source": [
        "Defina o nome da pasta onde contém as sub-pastas referente aos 3 tipos de classe. Se optar pelo armazenamento efêmero a pasta será ```raiox```. Se optar pelo Goolge Drive, indique o caminho da pasta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGs_ZyQBQg56"
      },
      "outputs": [],
      "source": [
        "## IMPLEMENTE\n",
        "divisao_treino_validacao = None\n",
        "nome_pasta_raiz_imagens = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hooi3PayQg56"
      },
      "source": [
        "O caminho abaixo da pasta ```raiox``` pode ser alterado caso você opte por utilizar uma pasta específica do seu Google Drive. Neste caso, certifique que dentro delas tem as sub-pastas referentes as imagens normal, pneumonia bacteriana e viral."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGZ6l5_mQg56"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(validation_split=divisao_treino_validacao)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    nome_pasta_raiz_imagens,\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",\n",
        "    color_mode=\"rgb\",\n",
        "    target_size=(224,224),\n",
        "    subset=\"training\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05h7XApxQg56"
      },
      "outputs": [],
      "source": [
        "val_generator = train_datagen.flow_from_directory(\n",
        "    nome_pasta_raiz_imagens,\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",\n",
        "    color_mode=\"rgb\",\n",
        "    target_size=(224,224),\n",
        "    subset=\"validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keh2XSnvQg56"
      },
      "outputs": [],
      "source": [
        "train_generator.class_indices, val_generator.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7nVrSeRQg56"
      },
      "source": [
        "## 4.4 Modelos de transfer learning\n",
        "\n",
        "O Keras já possui classes especializadas para os seguintes modelos de deep-learning treinados com o conjunto de dados [ImageNet](http://www.image-net.org/):\n",
        "  \n",
        "* Xception\n",
        "* VGG16\n",
        "* VGG19\n",
        "* ResNet50\n",
        "* InceptionV3\n",
        "* InceptionResNetV2\n",
        "* MobileNet\n",
        "* DenseNet\n",
        "* NASNet\n",
        "* MobileNetV2\n",
        "\n",
        "Mais detalhes, veja na [documentação do Keras](https://keras.io/applications/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF1W45tBQg57"
      },
      "source": [
        "Para este estudo, vamos utilizar para avaliação as seguintes arquiteturas: RestNet50, VGG15 e VGG19."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAuAGha6Qg57"
      },
      "source": [
        "## 4.5 Indicadores de desempenho\n",
        "\n",
        "O Keras não possui os indicadores de desempenho como precisão, sensibilidade e pontuação f1 por padrão, portanto precisamos implementar externamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngrIfvZnQg57"
      },
      "outputs": [],
      "source": [
        "def recall_score(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_score(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSz65NohQg57"
      },
      "source": [
        "### 4.5.1 Arquitetura ResNet50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZh7Z5LsQg57"
      },
      "source": [
        "**Pergunta**: Explique como é constituída a arquitetura do ResNet50? *Utilize, se necessário, gráficos, projetos que utilizam essa arquitetura. Detalhe também sua topologia em camadas e mostre quais as situações essa arquitetura pode ter mais êxito e quais cenários não tem.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_3draKVQg57"
      },
      "source": [
        "**Resposta**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0L6NtzgQg57"
      },
      "source": [
        "A técnica de transfer learning consiste de utilizar o mesmo modelo e treiná-lo para outas imagens. Por tal motivo, excluímos a última camada para modelar com as classes que definimos, ou seja, **controle**, **bacteriana** e **viral**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kelwE2aCQg57"
      },
      "source": [
        "Informe a quantidade de classes a serem classificadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GGEqYodQg57"
      },
      "outputs": [],
      "source": [
        "## IMPLEMENTE\n",
        "\n",
        "qtde_classes = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj7htCTtQg57"
      },
      "outputs": [],
      "source": [
        "conv_base = ResNet50(include_top=False)\n",
        "\n",
        "for layer in conv_base.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozU39y36Qg57"
      },
      "outputs": [],
      "source": [
        "x = conv_base.output\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "predictions = layers.Dense(qtde_classes, activation='softmax')(x)\n",
        "model = Model(conv_base.input, predictions)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1FzU9SVQg57"
      },
      "outputs": [],
      "source": [
        "optimizer = optimizers.Adam()\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[precision_score, recall_score, f1_score])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwEjKJSsQg58"
      },
      "source": [
        "O número de épocas define quantas vezes o modelo irá treinar e validar o erro, assim ajustando os pesos para melhor convergência.\n",
        "Escolha o número adequado de épocas para alcançarmos pelo menos **70% de precisão de validação**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Se-dax9TQg58"
      },
      "outputs": [],
      "source": [
        "## IMPLEMENTE\n",
        "\n",
        "qtde_epocas = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5DIk0YDQg58"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_generator, epochs=qtde_epocas, validation_steps=5, steps_per_epoch=5,\n",
        "                    validation_data=val_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yeYm7XNQg58"
      },
      "source": [
        "Um modelo que converge bem possui o gráfico de perda (*loss*) descendente e os gráfico de precisão (*precision*), sensibilidade (*recall*) e pontuação f1 (*f1 score*) em acendente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RisN-1v4Qg58"
      },
      "outputs": [],
      "source": [
        "# Exibindo dados de Precisão\n",
        "plt.plot(history.history['precision_score'])\n",
        "plt.plot(history.history['val_precision_score'])\n",
        "plt.title('model precision')\n",
        "plt.ylabel('precision')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Exibindo dados de Sensibilidade\n",
        "plt.plot(history.history['recall_score'])\n",
        "plt.plot(history.history['val_recall_score'])\n",
        "plt.title('model recall')\n",
        "plt.ylabel('recall')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Exibindo dados de F1 Score\n",
        "plt.plot(history.history['f1_score'])\n",
        "plt.plot(history.history['val_f1_score'])\n",
        "plt.title('model f1_score')\n",
        "plt.ylabel('f1_score')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Exibindo dados de Perda\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vMFj0UvQg58"
      },
      "source": [
        "**Pergunta**: Avalie os gráficos de perda (*loss*), precisão (*precision*), sensibilidade (*recall*) e pontuação f1 (*f1 score*)  e explique o comportamento de ambos no que tange a convergência do modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pkae0fJxQg58"
      },
      "source": [
        "**Resposta**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT-n4t4_Qg58"
      },
      "source": [
        "**Pergunta**: Quais são os valores de **precisão (precision)**, **sensibilidade (recall)** de validação?\n",
        "\n",
        "*Estes valores são exibidos durante o treinamento, utilize a última saída, exemplo:*\n",
        "\n",
        "```\n",
        "Epoch 10/10 [==============================] - 45s 9s/step - loss: 0.1234 - precision_score: 0.9742 - recall_score: 0.9683 - f1_score: 0.9712 - val_loss: 0.8819 - val_precision_score: 0.6912 - val_recall_score: 0.5649 - val_f1_score: 0.6216```\n",
        "\n",
        "No caso acima, o valor de precisão, sensibilidade e pontuação de validação são, respectivamente, 69,12%, 56,49% e 62,16%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCShGF1QQg58"
      },
      "source": [
        "**Resposta**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx5bRXd7Qg59"
      },
      "source": [
        "### 4.5.2 Arquitetura VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkVSD3CxQg59"
      },
      "source": [
        "**Pergunta**: Explique como é constituída a arquitetura do VGG16? *Utilize, se necessário, gráficos, projetos que utilizam essa arquitetura. Detalhe também sua topologia em camadas e mostre quais as situações essa arquitetura pode ter mais êxito e quais cenários não tem.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdOnWN1yQg59"
      },
      "source": [
        "**Resposta**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiTVSc_WQg59"
      },
      "outputs": [],
      "source": [
        "conv_base = VGG16(include_top=False)\n",
        "\n",
        "for layer in conv_base.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G51EfefsQg59"
      },
      "outputs": [],
      "source": [
        "x = conv_base.output\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "predictions = layers.Dense(qtde_classes, activation='softmax')(x)\n",
        "model = Model(conv_base.input, predictions)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2a9tbm2mQg59"
      },
      "outputs": [],
      "source": [
        "optimizer = optimizers.Adam()\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[precision_score, recall_score, f1_score])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8OncOuDQg59"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_generator, epochs=qtde_epocas, validation_steps=5, steps_per_epoch=5,\n",
        "                    validation_data=val_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWXDTRgBQg59"
      },
      "source": [
        "Um modelo que converge bem possui o gráfico de perda (*loss*) descendente e os gráfico de precisão (*precision*), sensibilidade (*recall*) e pontuação f1 (*f1 score*) em acendente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfBvdUxOQg59"
      },
      "outputs": [],
      "source": [
        "# Exibindo dados de Precisão\n",
        "plt.plot(history.history['precision_score'])\n",
        "plt.plot(history.history['val_precision_score'])\n",
        "plt.title('model precision')\n",
        "plt.ylabel('precision')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Exibindo dados de Sensibilidade\n",
        "plt.plot(history.history['recall_score'])\n",
        "plt.plot(history.history['val_recall_score'])\n",
        "plt.title('model recall')\n",
        "plt.ylabel('recall')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Exibindo dados de F1 Score\n",
        "plt.plot(history.history['f1_score'])\n",
        "plt.plot(history.history['val_f1_score'])\n",
        "plt.title('model f1_score')\n",
        "plt.ylabel('f1_score')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Exibindo dados de Perda\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI0ewkqoQg59"
      },
      "source": [
        "**Pergunta**: Avalie os gráficos de perda (*loss*), precisão (*precision*), sensibilidade (*recall*) e pontuação f1 (*f1 score*)  e explique o comportamento de ambos no que tange a convergência do modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxqhBaDBQg59"
      },
      "source": [
        "**Resposta**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LQo7H2eQg59"
      },
      "source": [
        "**Pergunta**: Quais são os valores de **precisão (precision)**, **sensibilidade (recall)** de validação?\n",
        "\n",
        "*Estes valores são exibidos durante o treinamento, utilize a última saída, exemplo:*\n",
        "\n",
        "```\n",
        "Epoch 10/10 [==============================] - 45s 9s/step - loss: 0.1234 - precision_score: 0.9742 - recall_score: 0.9683 - f1_score: 0.9712 - val_loss: 0.8819 - val_precision_score: 0.6912 - val_recall_score: 0.5649 - val_f1_score: 0.6216```\n",
        "\n",
        "No caso acima, o valor de precisão, sensibilidade e pontuação de validação são, respectivamente, 69,12%, 56,49% e 62,16%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOGVo7_oQg59"
      },
      "source": [
        "**Resposta**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCW0lENuQg59"
      },
      "source": [
        "### 4.5.3 Arquitetura VGG19"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRbx7mQ1Qg59"
      },
      "source": [
        "**Pergunta**: Explique como é constituída a arquitetura do VGG19? *Utilize, se necessário, gráficos, projetos que utilizam essa arquitetura. Detalhe também sua topologia em camadas e mostre quais as situações essa arquitetura pode ter mais êxito e quais cenários não tem.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNJv3FXZQg59"
      },
      "source": [
        "**Resposta**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdjTbeJ_Qg59"
      },
      "outputs": [],
      "source": [
        "conv_base = VGG19(include_top=False)\n",
        "\n",
        "for layer in conv_base.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPgf8fCfQg59"
      },
      "outputs": [],
      "source": [
        "x = conv_base.output\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "predictions = layers.Dense(qtde_classes, activation='softmax')(x)\n",
        "model = Model(conv_base.input, predictions)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Br78ZbybQg59"
      },
      "outputs": [],
      "source": [
        "optimizer = optimizers.Adam()\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[precision_score, recall_score, f1_score])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmqRL9lCQg5-"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_generator, epochs=qtde_epocas, validation_steps=5, steps_per_epoch=5,\n",
        "                    validation_data=val_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D1CxIQxQg5-"
      },
      "source": [
        "Um modelo que converge bem possui o gráfico de perda (*loss*) descendente e os gráfico de precisão (*precision*), sensibilidade (*recall*) e pontuação f1 (*f1 score*) em acendente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdQIeGW-Qg5-"
      },
      "outputs": [],
      "source": [
        "# Exibindo dados de Precisão\n",
        "plt.plot(history.history['precision_score'])\n",
        "plt.plot(history.history['val_precision_score'])\n",
        "plt.title('model precision')\n",
        "plt.ylabel('precision')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Exibindo dados de Sensibilidade\n",
        "plt.plot(history.history['recall_score'])\n",
        "plt.plot(history.history['val_recall_score'])\n",
        "plt.title('model recall')\n",
        "plt.ylabel('recall')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Exibindo dados de F1 Score\n",
        "plt.plot(history.history['f1_score'])\n",
        "plt.plot(history.history['val_f1_score'])\n",
        "plt.title('model f1_score')\n",
        "plt.ylabel('f1_score')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Exibindo dados de Perda\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQxQfOZVQg5-"
      },
      "source": [
        "**Pergunta**: Avalie os gráficos de perda (*loss*), precisão (*precision*), sensibilidade (*recall*) e pontuação f1 (*f1 score*)  e explique o comportamento de ambos no que tange a convergência do modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QzRPdlPQg5-"
      },
      "source": [
        "**Resposta**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiDIEJRCQg5-"
      },
      "source": [
        "**Pergunta**: Quais são os valores de **precisão (precision)**, **sensibilidade (recall)** de validação?\n",
        "\n",
        "*Estes valores são exibidos durante o treinamento, utilize a última saída, exemplo:*\n",
        "\n",
        "```\n",
        "Epoch 10/10 [==============================] - 45s 9s/step - loss: 0.1234 - precision_score: 0.9742 - recall_score: 0.9683 - f1_score: 0.9712 - val_loss: 0.8819 - val_precision_score: 0.6912 - val_recall_score: 0.5649 - val_f1_score: 0.6216```\n",
        "\n",
        "No caso acima, o valor de precisão, sensibilidade e pontuação de validação são, respectivamente, 69,12%, 56,49% e 62,16%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FIdPxpWQg5-"
      },
      "source": [
        "**Resposta**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_a-2ZiGQg5-"
      },
      "source": [
        "## 4.6 Compartivo de arquiteturas\n",
        "\n",
        "Preencha a tabela abaixo com os valores dos indicadores de performance apresentados.\n",
        "\n",
        "_O cálculo do F1-Score é dado por 2 * (Precisão * Sensibilidade) / (Precisão + Sensibilidade)._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03FI1IR4Qg5-"
      },
      "source": [
        "| Modelo   | Precisão (*Precision*) | Sensibilidade (*Recall*) | F1-Score |\n",
        "|----------|----------|---------------|----------|\n",
        "| ResNet50 | XX %     | XX %          | XX %     |\n",
        "| VGG16    | XX %     | XX %          | XX %     |\n",
        "| VGG19    | XX %     | XX %          | XX %     |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37_Fmh0RQg5-"
      },
      "source": [
        "## 4.7 Conclusões\n",
        "\n",
        "Analise os resultados da tabela de indicadores do comparativo de arquiteturas e explique os principais motivos pelos quais cada modelo obteve cada resultado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA1nkbS_Qg5-"
      },
      "source": [
        "**Respota**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykZAOAYcQg5-"
      },
      "source": [
        "## 4.8 Abordagem adicional (obrigatório)\n",
        "\n",
        "Considerando os outros classificadores, escolha outro que ainda não foi utilizado, implemente abaixo. Ao final compare os resultados e explique os resultados.\n",
        "\n",
        "_Não se esquece de utilizar as importações adequadas para cada modelo.\n",
        "A forma de implementação deve respeitar as mesmas condições como valor de split e quantidade de imagens para poder comparar os modelos._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBEqXy12Qg5-"
      },
      "outputs": [],
      "source": [
        "#IMPLEMENTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbOoenGzQg5-"
      },
      "source": [
        "### 4.8.1 Conclusões sobre a abordagem adicional\n",
        "\n",
        "Como seu modelo performou em comparação com os demais modelos anteriores? Justifique sua resposta levando em consideração a arquitetura respectiva."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zapGSiF-Qg5-"
      },
      "source": [
        "**Resposta**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsnHaPEIQg5-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}